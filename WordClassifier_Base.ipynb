{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:06.166926Z",
     "start_time": "2024-07-07T15:06:06.163948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# spell correction\n",
    "# normalizer"
   ],
   "id": "ea197c5e5b2ff80f",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:06.373558Z",
     "start_time": "2024-07-07T15:06:06.367454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "from hazm import InformalNormalizer, Normalizer"
   ],
   "id": "caf8ed523a74f5cb",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:06.618712Z",
     "start_time": "2024-07-07T15:06:06.611570Z"
    }
   },
   "cell_type": "code",
   "source": "tqdm.pandas()",
   "id": "3d3729624c59f9b7",
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:07.624054Z",
     "start_time": "2024-07-07T15:06:07.108927Z"
    }
   },
   "source": [
    "prepared_data: pd.DataFrame = pd.read_csv('datasets/taghche.csv')\n",
    "prepared_data = prepared_data[['comment', 'bookname']]"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:07.639704Z",
     "start_time": "2024-07-07T15:06:07.631864Z"
    }
   },
   "cell_type": "code",
   "source": "prepared_data.head()",
   "id": "c7c751dd317e7678",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             comment  \\\n",
       "0  Ø§Ø³Ù… Ú©ØªØ§Ø¨   No one writes to the Colonel\\nØªØ±Ø¬Ù…Ø´...   \n",
       "1  Ø·Ø§Ù‚Ú†Ù‡ Ø¹Ø²ÛŒØ²ØŒÙ†Ø§Ù… Ú©ØªØ§Ø¨\"Ú©Ø³ÛŒ Ø¨Ù‡ Ø³Ø±Ù‡Ù†Ú¯ Ù†Ø§Ù…Ù‡ Ù†Ù…ÛŒÙ†ÙˆÛŒØ³Ø¯...   \n",
       "2  Ø¨Ù†Ø¸Ø±Ù… Ø§ÛŒÙ† Ø§Ø«Ø± Ù…Ø§Ø±Ú©Ø² Ø®ÛŒÙ„ÛŒ Ø§Ø² ØµØ¯ Ø³Ø§Ù„ ØªÙ†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨...   \n",
       "3  Ø¨Ù‡ Ù†Ø¸Ø± Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ù…ÛŒÙˆÙ…Ø¯ Ø§Ù…Ø§ Ù…Ù† Ø§Ø² ØªØ±Ø¬Ù…Ø´ Ø®ÙˆØ´Ù… Ù†ÛŒ...   \n",
       "4                                      Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ø§Ø³Øª   \n",
       "\n",
       "                            bookname  \n",
       "0  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  \n",
       "1  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  \n",
       "2  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  \n",
       "3  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  \n",
       "4  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>bookname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø§Ø³Ù… Ú©ØªØ§Ø¨   No one writes to the Colonel\\nØªØ±Ø¬Ù…Ø´...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø·Ø§Ù‚Ú†Ù‡ Ø¹Ø²ÛŒØ²ØŒÙ†Ø§Ù… Ú©ØªØ§Ø¨\"Ú©Ø³ÛŒ Ø¨Ù‡ Ø³Ø±Ù‡Ù†Ú¯ Ù†Ø§Ù…Ù‡ Ù†Ù…ÛŒÙ†ÙˆÛŒØ³Ø¯...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø¨Ù†Ø¸Ø±Ù… Ø§ÛŒÙ† Ø§Ø«Ø± Ù…Ø§Ø±Ú©Ø² Ø®ÛŒÙ„ÛŒ Ø§Ø² ØµØ¯ Ø³Ø§Ù„ ØªÙ†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¨Ù‡ Ù†Ø¸Ø± Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ù…ÛŒÙˆÙ…Ø¯ Ø§Ù…Ø§ Ù…Ù† Ø§Ø² ØªØ±Ø¬Ù…Ø´ Ø®ÙˆØ´Ù… Ù†ÛŒ...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ø§Ø³Øª</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:09.709450Z",
     "start_time": "2024-07-07T15:06:09.703192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars_stop_words = ''\n",
    "with open('stopwords/chars.txt', 'r', encoding='utf-8') as file:\n",
    "    chars_stop_words = ''.join(file.read().splitlines())\n",
    "\n",
    "chars_stop_words = chars_stop_words.replace('[', '\\[')\n",
    "chars_stop_words = chars_stop_words.replace(']', '\\]')\n",
    "chars_pattern = re.compile(f'[{chars_stop_words}]')\n",
    "chars_pattern"
   ],
   "id": "bd59dc1f5b219367",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[\\ufeff!\"#()*,-./:\\[\\]Â«Â»ØŒØ›ØŸÛ°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹â€¦$Ù’ÙŒÙÙ‹ÙÙÙÙ‘Ø¡Ù”Ù°ï·¼]', re.UNICODE)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:10.065940Z",
     "start_time": "2024-07-07T15:06:10.058052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "emojis_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\")\n",
    "emojis_pattern"
   ],
   "id": "f3dfc0ccaed98d21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿ğŸš€-\\U0001f6ff\\U0001f1e0-ğŸ‡¿]+', re.UNICODE)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:06:11.832560Z",
     "start_time": "2024-07-07T15:06:11.813027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(text):\n",
    "    global chars_pattern, emojis_pattern\n",
    "    \n",
    "    text = chars_pattern.sub(r' ', text)\n",
    "    text = emojis_pattern.sub(r' ', text)\n",
    "    return informal_normalizer_function(text)\n",
    "\n",
    "\n",
    "# customizing InformalNormalizer().normalize()\n",
    "# For seeing differences, you can see InformalNormalizer().normalize() method\n",
    "def informal_normalizer_function(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    informal_normalizer = InformalNormalizer()\n",
    "    text = Normalizer.normalize(informal_normalizer, text)\n",
    "    sents = [\n",
    "        informal_normalizer.word_tokenizer.tokenize(sentence)\n",
    "        for sentence in informal_normalizer.sent_tokenizer.tokenize(text)\n",
    "    ]\n",
    "\n",
    "    normalized = [[informal_normalizer.normalized_word(word)[0] for word in sent] for sent in sents]\n",
    "    normalized = np.array(normalized, dtype=object)\n",
    "    return np.hstack(normalized)"
   ],
   "id": "b5a5f26fadc093b3",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:08:13.894553Z",
     "start_time": "2024-07-07T15:06:13.870195Z"
    }
   },
   "cell_type": "code",
   "source": "prepared_data['comment'] = prepared_data['comment'].progress_apply(preprocess)",
   "id": "cf3e30caaf92a2c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69829 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b075e62be94a7190f0f0fce4aafb85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[115], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m prepared_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcomment\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mprepared_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcomment\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogress_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:805\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001B[0;34m(df, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Apply the provided function (in **kwargs)\u001B[39;00m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_function\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    807\u001B[0m     t\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4630\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4520\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4521\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4522\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4525\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4526\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4527\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4528\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4529\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4628\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4629\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4630\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py:1025\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py:1076\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1074\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1075\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1076\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2834\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:800\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    795\u001B[0m     \u001B[38;5;66;03m# update tbar correctly\u001B[39;00m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001B[39;00m\n\u001B[1;32m    797\u001B[0m     \u001B[38;5;66;03m# on the first column/row to decide whether it can\u001B[39;00m\n\u001B[1;32m    798\u001B[0m     \u001B[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001B[39;00m\n\u001B[1;32m    799\u001B[0m     t\u001B[38;5;241m.\u001B[39mupdate(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[114], line 6\u001B[0m, in \u001B[0;36mpreprocess\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m      4\u001B[0m text \u001B[38;5;241m=\u001B[39m chars_pattern\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[1;32m      5\u001B[0m text \u001B[38;5;241m=\u001B[39m emojis_pattern\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minformal_normalizer_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[114], line 14\u001B[0m, in \u001B[0;36minformal_normalizer_function\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minformal_normalizer_function\u001B[39m(text):\n\u001B[1;32m     12\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(text)\n\u001B[0;32m---> 14\u001B[0m     informal_normalizer \u001B[38;5;241m=\u001B[39m \u001B[43mInformalNormalizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m     text \u001B[38;5;241m=\u001B[39m Normalizer\u001B[38;5;241m.\u001B[39mnormalize(informal_normalizer, text)\n\u001B[1;32m     16\u001B[0m     sents \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     17\u001B[0m         informal_normalizer\u001B[38;5;241m.\u001B[39mword_tokenizer\u001B[38;5;241m.\u001B[39mtokenize(sentence)\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m sentence \u001B[38;5;129;01min\u001B[39;00m informal_normalizer\u001B[38;5;241m.\u001B[39msent_tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text)\n\u001B[1;32m     19\u001B[0m     ]\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hazm/informal_normalizer.py:41\u001B[0m, in \u001B[0;36mInformalNormalizer.__init__\u001B[0;34m(self, verb_file, word_file, seperation_flag, **kargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39milemmatizer \u001B[38;5;241m=\u001B[39m InformalLemmatizer()\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstemmer \u001B[38;5;241m=\u001B[39m Stemmer()\n\u001B[0;32m---> 41\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msent_tokenizer \u001B[38;5;241m=\u001B[39m SentenceTokenizer()\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mword_tokenizer \u001B[38;5;241m=\u001B[39m WordTokenizer()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hazm/normalizer.py:54\u001B[0m, in \u001B[0;36mNormalizer.__init__\u001B[0;34m(self, correct_spacing, remove_diacritics, remove_specials_chars, decrease_repeated_chars, persian_style, persian_numbers, unicodes_replacement, seperate_mi)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranslation_dst \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mÛŒÚ©Ú©ÛŒÛŒÛŒÚ©ÛŒØ¨Ù‚ÙˆÛŒØªØªØ¨ØªØªØªØ¨Ø­Ø§ÙˆÙˆÛŒØªØªØ¨ØªØªØªØ¨Ø­Ø­Ø­Ú†Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø±Ø±Ø±Ø±Ø±Ø±Ø±Ø±Ø³Ø³Ø³ØµØµØ·Ø¹ÙÙÙÙÙÙÙ‚Ù‚Ú©Ú©Ú©Ú©Ú©Ú¯Ú¯Ú¯Ú¯Ú¯Ù„Ù„Ù„Ù„Ù†Ù†Ù†Ù†Ù†Ù‡Ú†Ù‡Ù‡Ù‡ÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÛŒÛŒÛŒÛŒÛŒÛŒÙ‡Ø¯Ø±Ø´Ø¶ØºÙ‡Ø¨Ø¨Ø¨Ø¨Ø¨Ø¨Ø¨Ø­Ø­Ø¯Ø¯Ø±Ø³Ø¹Ø¹Ø¹ÙÙÚ©Ú©Ú©Ù…Ù…Ù†Ù†Ù†Ù„Ø±Ø±Ø³Ø­Ø­Ø³Ø±Ø­Ø§Ø§ÛŒÛŒÛŒÙˆÙˆÛŒÛŒØ­Ø³Ø³Ú©Ø¨Ø¨Ø¬Ø·ÙÙ‚Ù„Ù…ÛŒÛŒØ±ÙˆØ¯ØµÚ¯ÙˆÛŒØ²Ø¹Ú©Ø¨Ù¾ØªØ±ÛŒÙÙ‚Ù†Ø§Ø§Ø¨Ø¨Ø¨Ø¨Ù¾Ù¾Ù¾Ù¾Ø¨Ø¨Ø¨Ø¨ØªØªØªØªØªØªØªØªØªØªØªØªÙÙÙÙØ­Ø­Ø­Ø­Ø­Ø­Ø­Ø­Ú†Ú†Ú†Ú†Ú†Ú†Ú†Ú†Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ú˜Ú˜Ø±Ø±Ú©Ú©Ú©Ú©Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ú¯Ù†Ù†Ù†Ù†Ù†Ù†Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ÛŒÛŒÛŒÛŒØ¡Ø§Ø§Ø§ÙˆÙˆØ§Ø§ÛŒÛŒÛŒÛŒØ§Ø§Ø¨Ø¨Ø¨Ø¨ØªØªØªØªØ«Ø«Ø«Ø«Ø¬Ø¬Ø¬Ø¬Ø­Ø­Ø­Ø­Ø®Ø®Ø®Ø®Ø¯Ø¯Ø°Ø°Ø±Ø±Ø²Ø²Ø³Ø³Ø³Ø³Ø´Ø´Ø´Ø´ØµØµØµØµØ¶Ø¶Ø¶Ø¶Ø·Ø·Ø·Ø·Ø¸Ø¸Ø¸Ø¸Ø¹Ø¹Ø¹Ø¹ØºØºØºØºÙÙÙÙÙ‚Ù‚Ù‚Ù‚Ú©Ú©Ú©Ú©Ù„Ù„Ù„Ù„Ù…Ù…Ù…Ù…Ù†Ù†Ù†Ù†Ù‡Ù‡Ù‡Ù‡ÙˆÙˆÛŒÛŒÛŒÛŒÛŒÛŒÛŒÚ©ÛŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     51\u001B[0m )\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_correct_spacing \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decrease_repeated_chars:\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mWordTokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjoin_verb_parts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwords \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mwords\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persian_number:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hazm/word_tokenizer.py:103\u001B[0m, in \u001B[0;36mWordTokenizer.__init__\u001B[0;34m(self, words_file, verbs_file, join_verb_parts, join_abbreviations, separate_emoji, replace_links, replace_ids, replace_emails, replace_numbers, replace_hashtags)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;66;03m# NOTE: python2.7 does not support unicodes with \\w\u001B[39;00m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhashtag_repl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTAG \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m m\u001B[38;5;241m.\u001B[39mgroup(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwords \u001B[38;5;241m=\u001B[39m {item[\u001B[38;5;241m0\u001B[39m]: (item[\u001B[38;5;241m1\u001B[39m], item[\u001B[38;5;241m2\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m \u001B[43mwords_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords_file\u001B[49m\u001B[43m)\u001B[49m}\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m join_verb_parts:\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter_verbs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    107\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØ§Ù…\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØ§ÛŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mÙ†Ø®ÙˆØ§Ù‡Ù†Ø¯_Ø´Ø¯\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m     }\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hazm/utils.py:48\u001B[0m, in \u001B[0;36mwords_list\u001B[0;34m(words_file)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Path\u001B[38;5;241m.\u001B[39mopen(words_file, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m words_file:\n\u001B[1;32m     47\u001B[0m     items \u001B[38;5;241m=\u001B[39m [line\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m words_file]\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m     49\u001B[0m         (item[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mint\u001B[39m(item[\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28mtuple\u001B[39m(item[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m items\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(item) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m     52\u001B[0m     ]\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hazm/utils.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Path\u001B[38;5;241m.\u001B[39mopen(words_file, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m words_file:\n\u001B[1;32m     47\u001B[0m     items \u001B[38;5;241m=\u001B[39m [line\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m words_file]\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m---> 49\u001B[0m         (\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m, \u001B[38;5;28mint\u001B[39m(item[\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28mtuple\u001B[39m(item[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m items\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(item) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m     52\u001B[0m     ]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:08:13.897085Z",
     "start_time": "2024-07-07T15:08:13.896909Z"
    }
   },
   "cell_type": "code",
   "source": "prepared_data.head()",
   "id": "2e1d673b6c484593",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:00:44.957111Z",
     "start_time": "2024-07-07T15:00:44.134230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ALL_PARTS_LEN = 18\n",
    "crawled_data: pd.DataFrame = pd.read_csv('datasets/books data/books_data_part_1.csv')\n",
    "for i in range(2, ALL_PARTS_LEN + 1):\n",
    "    crawled_data = pd.concat([crawled_data, pd.read_csv(f'datasets/books data/books_data_part_{i}.csv')],\n",
    "                             ignore_index=True)"
   ],
   "id": "ddb3e98c34282776",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:00:45.062517Z",
     "start_time": "2024-07-07T15:00:44.959340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sort authors in order to drop duplicates\n",
    "new_author_function = lambda x: ' $ '.join(sorted(str(x).split(' $ ')))\n",
    "crawled_data['author'] = crawled_data['author'].apply(new_author_function)"
   ],
   "id": "9fca1a1b98601fb2",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:00:45.511483Z",
     "start_time": "2024-07-07T15:00:45.318093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "before_dropping = len(crawled_data)\n",
    "crawled_data = crawled_data.drop_duplicates()\n",
    "print(f'Dropped {before_dropping - len(crawled_data)} duplicates.')"
   ],
   "id": "542c164cfa0c2a69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2256 duplicates.\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:00:54.635362Z",
     "start_time": "2024-07-07T15:00:46.479339Z"
    }
   },
   "cell_type": "code",
   "source": "crawled_data = crawled_data.groupby(['name', 'author']).agg({'translator': set, 'publisher': set}).reset_index()",
   "id": "6e49fc20f57ef364",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:03:39.033605Z",
     "start_time": "2024-07-07T15:03:38.894405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_author_function = lambda x: set(x.split(' $ '))\n",
    "crawled_data['author'] = crawled_data['author'].apply(new_author_function)"
   ],
   "id": "ff1ac4627815bd4d",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:03:39.547301Z",
     "start_time": "2024-07-07T15:03:39.526647Z"
    }
   },
   "cell_type": "code",
   "source": "crawled_data.head()",
   "id": "cc7ff06613b1d25d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                name  \\\n",
       "0                              \\nØ³Ù„ÙˆÚ© Ù…Ø¹Ù†ÙˆÛŒ Ø§Ø¨Ù† Ø¹Ø±Ø¨ÛŒ   \n",
       "1   100 Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§Ø®ØªÙ„Ø§Ù„ Ø§ÙØ³Ø±Ø¯Ú¯ÛŒ ÛŒØ§ Ø¯Ùˆ Ù‚...   \n",
       "2   100 Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù†Ù‚Øµ ØªÙˆØ¬Ù‡/Ø¨ÛŒØ´ ÙØ¹Ø§Ù„ÛŒ Ø¨Ø²Ø±...   \n",
       "3   12 Ø´ÛŒÙˆÙ‡ Ø§Ø³Ø§Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ Ø³ÙˆØ§Ø¯ Ø±Ø³Ø§Ù†Ù‡ Ùˆ ØªÙÚ©Ø± Ø§Ù†...   \n",
       "4   25 Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨Ú†Ù‡ Ú¯Ø§Ù†Ù‡ Ø§ÛŒ Ú©Ù‡ Ø²ÙˆØ¬ Ù‡Ø§ Ø¯Ø± Ø²Ù†Ø¯Ú¯ÛŒ Ø²Ù†Ø§Ø´...   \n",
       "\n",
       "                               author             translator        publisher  \n",
       "0  {ÙˆÛŒÙ„ÛŒØ§Ù… Ø³ÛŒ. Ú†ÛŒØªÛŒÚ©, Ø¬Ø§Ù† Ø¬ÛŒ Ø³ÙˆÙ„ÛŒÙˆØ§Ù†}           {Ø­Ø³ÛŒÙ† Ù…Ø±ÛŒØ¯ÛŒ}  {Ø§Ù†ØªØ´Ø§Ø±Ø§Øª Ø¬Ø§Ù…ÛŒ}  \n",
       "1                    {Ù„ÛŒÙ†Ø¯Ø§ Ú©Ø§Ú©Ø±ÙˆØ±ØªÛŒ}                  {nan}      {Ù†Ø´Ø± Ø¯Ø§Ù†Ú˜Ù‡}  \n",
       "2                     {Ø¢ÙˆØ§ ØªÛŒ Ø¢Ù„Ø¨Ø±Ø´Øª}                  {nan}      {Ù†Ø´Ø± Ø¯Ø§Ù†Ú˜Ù‡}  \n",
       "3                         {Ø³ÛŒØ¯Ù†ÛŒ Ø´ÛŒØ¨}     {Ù…Ø±Ø¬Ø§Ù† Ø§Ø±Ø¯Ø´ÛŒØ±Ø²Ø§Ø¯Ù‡}          {Ø³Ù…Ù†Ø¯Ø±}  \n",
       "4                     {Ù¾Ù„ Ø¯Ø¨Ù„ÛŒÙˆ Ú©Ù„Ù…Ù†}  {Ø¢Ø±Ù…Ø§Ù†ÙˆØ´ Ø¨Ø§Ø¨Ø§Ø®Ø§Ù†ÛŒØ§Ù†Ø³}           {Ø¯Ù†ÛŒØ³}  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>translator</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nØ³Ù„ÙˆÚ© Ù…Ø¹Ù†ÙˆÛŒ Ø§Ø¨Ù† Ø¹Ø±Ø¨ÛŒ</td>\n",
       "      <td>{ÙˆÛŒÙ„ÛŒØ§Ù… Ø³ÛŒ. Ú†ÛŒØªÛŒÚ©, Ø¬Ø§Ù† Ø¬ÛŒ Ø³ÙˆÙ„ÛŒÙˆØ§Ù†}</td>\n",
       "      <td>{Ø­Ø³ÛŒÙ† Ù…Ø±ÛŒØ¯ÛŒ}</td>\n",
       "      <td>{Ø§Ù†ØªØ´Ø§Ø±Ø§Øª Ø¬Ø§Ù…ÛŒ}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§Ø®ØªÙ„Ø§Ù„ Ø§ÙØ³Ø±Ø¯Ú¯ÛŒ ÛŒØ§ Ø¯Ùˆ Ù‚...</td>\n",
       "      <td>{Ù„ÛŒÙ†Ø¯Ø§ Ú©Ø§Ú©Ø±ÙˆØ±ØªÛŒ}</td>\n",
       "      <td>{nan}</td>\n",
       "      <td>{Ù†Ø´Ø± Ø¯Ø§Ù†Ú˜Ù‡}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100 Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù†Ù‚Øµ ØªÙˆØ¬Ù‡/Ø¨ÛŒØ´ ÙØ¹Ø§Ù„ÛŒ Ø¨Ø²Ø±...</td>\n",
       "      <td>{Ø¢ÙˆØ§ ØªÛŒ Ø¢Ù„Ø¨Ø±Ø´Øª}</td>\n",
       "      <td>{nan}</td>\n",
       "      <td>{Ù†Ø´Ø± Ø¯Ø§Ù†Ú˜Ù‡}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Ø´ÛŒÙˆÙ‡ Ø§Ø³Ø§Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ Ø³ÙˆØ§Ø¯ Ø±Ø³Ø§Ù†Ù‡ Ùˆ ØªÙÚ©Ø± Ø§Ù†...</td>\n",
       "      <td>{Ø³ÛŒØ¯Ù†ÛŒ Ø´ÛŒØ¨}</td>\n",
       "      <td>{Ù…Ø±Ø¬Ø§Ù† Ø§Ø±Ø¯Ø´ÛŒØ±Ø²Ø§Ø¯Ù‡}</td>\n",
       "      <td>{Ø³Ù…Ù†Ø¯Ø±}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨Ú†Ù‡ Ú¯Ø§Ù†Ù‡ Ø§ÛŒ Ú©Ù‡ Ø²ÙˆØ¬ Ù‡Ø§ Ø¯Ø± Ø²Ù†Ø¯Ú¯ÛŒ Ø²Ù†Ø§Ø´...</td>\n",
       "      <td>{Ù¾Ù„ Ø¯Ø¨Ù„ÛŒÙˆ Ú©Ù„Ù…Ù†}</td>\n",
       "      <td>{Ø¢Ø±Ù…Ø§Ù†ÙˆØ´ Ø¨Ø§Ø¨Ø§Ø®Ø§Ù†ÛŒØ§Ù†Ø³}</td>\n",
       "      <td>{Ø¯Ù†ÛŒØ³}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:03:51.146651Z",
     "start_time": "2024-07-07T15:03:50.939475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.merge(prepared_data, crawled_data, left_on='bookname', right_on='name')\n",
    "data = data.drop(columns=['bookname'])"
   ],
   "id": "c4b8b167c9f9957e",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:03:51.875578Z",
     "start_time": "2024-07-07T15:03:51.861709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Prepared data: {len(prepared_data)}\\nCrawled data: {len(crawled_data)}\\nMerged data: {len(data)}')\n",
    "data.head()"
   ],
   "id": "2bf38c6a6e056e2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data: 69829\n",
      "Crawled data: 166540\n",
      "Merged data: 88828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             comment  \\\n",
       "0  Ø§Ø³Ù… Ú©ØªØ§Ø¨   No one writes to the Colonel\\nØªØ±Ø¬Ù…Ø´...   \n",
       "1  Ø·Ø§Ù‚Ú†Ù‡ Ø¹Ø²ÛŒØ²ØŒÙ†Ø§Ù… Ú©ØªØ§Ø¨\"Ú©Ø³ÛŒ Ø¨Ù‡ Ø³Ø±Ù‡Ù†Ú¯ Ù†Ø§Ù…Ù‡ Ù†Ù…ÛŒÙ†ÙˆÛŒØ³Ø¯...   \n",
       "2  Ø¨Ù†Ø¸Ø±Ù… Ø§ÛŒÙ† Ø§Ø«Ø± Ù…Ø§Ø±Ú©Ø² Ø®ÛŒÙ„ÛŒ Ø§Ø² ØµØ¯ Ø³Ø§Ù„ ØªÙ†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨...   \n",
       "3  Ø¨Ù‡ Ù†Ø¸Ø± Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ù…ÛŒÙˆÙ…Ø¯ Ø§Ù…Ø§ Ù…Ù† Ø§Ø² ØªØ±Ø¬Ù…Ø´ Ø®ÙˆØ´Ù… Ù†ÛŒ...   \n",
       "4                                      Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ø§Ø³Øª   \n",
       "\n",
       "                                name                 author      translator  \\\n",
       "0  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  {Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}  {Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}   \n",
       "1  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  {Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}  {Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}   \n",
       "2  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  {Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}  {Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}   \n",
       "3  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  {Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}  {Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}   \n",
       "4  Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯  {Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}  {Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}   \n",
       "\n",
       "                       publisher  \n",
       "0  {Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}  \n",
       "1  {Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}  \n",
       "2  {Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}  \n",
       "3  {Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}  \n",
       "4  {Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>translator</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø§Ø³Ù… Ú©ØªØ§Ø¨   No one writes to the Colonel\\nØªØ±Ø¬Ù…Ø´...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "      <td>{Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}</td>\n",
       "      <td>{Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}</td>\n",
       "      <td>{Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø·Ø§Ù‚Ú†Ù‡ Ø¹Ø²ÛŒØ²ØŒÙ†Ø§Ù… Ú©ØªØ§Ø¨\"Ú©Ø³ÛŒ Ø¨Ù‡ Ø³Ø±Ù‡Ù†Ú¯ Ù†Ø§Ù…Ù‡ Ù†Ù…ÛŒÙ†ÙˆÛŒØ³Ø¯...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "      <td>{Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}</td>\n",
       "      <td>{Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}</td>\n",
       "      <td>{Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø¨Ù†Ø¸Ø±Ù… Ø§ÛŒÙ† Ø§Ø«Ø± Ù…Ø§Ø±Ú©Ø² Ø®ÛŒÙ„ÛŒ Ø§Ø² ØµØ¯ Ø³Ø§Ù„ ØªÙ†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "      <td>{Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}</td>\n",
       "      <td>{Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}</td>\n",
       "      <td>{Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¨Ù‡ Ù†Ø¸Ø± Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ù…ÛŒÙˆÙ…Ø¯ Ø§Ù…Ø§ Ù…Ù† Ø§Ø² ØªØ±Ø¬Ù…Ø´ Ø®ÙˆØ´Ù… Ù†ÛŒ...</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "      <td>{Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}</td>\n",
       "      <td>{Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}</td>\n",
       "      <td>{Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ø§Ø³Øª</td>\n",
       "      <td>Ø³Ø±Ù‡Ù†Ú¯ Ú©Ø³ÛŒ Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒØ´ Ù†Ø§Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³Ø¯</td>\n",
       "      <td>{Ú¯Ø§Ø¨Ø±ÛŒÙ„ Ú¯Ø§Ø±Ø³ÛŒØ§ Ù…Ø§Ø±Ú©Ø²}</td>\n",
       "      <td>{Ù†Ø§Ø²Ù†ÛŒÙ† Ù†ÙˆØ°Ø±ÛŒ}</td>\n",
       "      <td>{Ù…ÙˆØ³Ø³Ù‡ ÙØ±Ù‡Ù†Ú¯ÛŒ Ù‡Ù†Ø±ÛŒ Ù†ÙˆØ±ÙˆØ² Ù‡Ù†Ø±}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T15:04:24.057647Z",
     "start_time": "2024-07-07T15:04:24.014272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "crawled_books = set(crawled_data['name'].values)\n",
    "prepared_books = prepared_data['bookname'].values\n",
    "\n",
    "unavailable_books = [book for book in prepared_books if book not in crawled_books]\n",
    "print(f'Unavailable books: {len(unavailable_books)}')"
   ],
   "id": "2c4ba25b104a2188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unavailable books: 8102\n",
      "Is the number of unavailable books equal to the difference between prepared and merged data?\n",
      "False\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Labeling",
   "id": "280620f9fb070b1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe44b9919ee2a11b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
